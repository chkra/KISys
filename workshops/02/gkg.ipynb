{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "\n",
    "# Set up your API keys\n",
    "GOOGLE_KG_API_KEY = 'your_google_kg_api_key'\n",
    "OPENAI_API_KEY = 'your_openai_api_key'\n",
    "\n",
    "# Define the function to query Google Knowledge Graph\n",
    "def query_knowledge_graph(query):\n",
    "    url = \"https://kgsearch.googleapis.com/v1/entities:search\"\n",
    "    params = {\n",
    "        'query': query,\n",
    "        'limit': 1,\n",
    "        'indent': True,\n",
    "        'key': GOOGLE_KG_API_KEY,\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    if 'itemListElement' in data and len(data['itemListElement']) > 0:\n",
    "        entity = data['itemListElement'][0]['result']\n",
    "        return entity.get('name', 'Unknown'), entity.get('description', 'No description available.')\n",
    "    else:\n",
    "        return \"Entity not found\", \"\"\n",
    "\n",
    "# Define the function to use GPT-3 for generating responses\n",
    "def generate_gpt_response(question):\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=question,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Main function to integrate the LLM and Knowledge Graph\n",
    "def knowledge_graph_llm_pipeline(query):\n",
    "    # Step 1: Query the knowledge graph\n",
    "    entity_name, entity_description = query_knowledge_graph(query)\n",
    "    \n",
    "    # Step 2: Generate a question for GPT-3 using the knowledge graph info\n",
    "    if entity_name != \"Entity not found\":\n",
    "        gpt_question = f\"What can you tell me about {entity_name}? {entity_description}\"\n",
    "    else:\n",
    "        gpt_question = f\"Tell me more about {query} in general.\"\n",
    "\n",
    "    # Step 3: Get a response from the LLM\n",
    "    gpt_response = generate_gpt_response(gpt_question)\n",
    "    \n",
    "    return {\n",
    "        'Entity': entity_name,\n",
    "        'Knowledge Graph Info': entity_description,\n",
    "        'LLM Response': gpt_response\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "query = \"Albert Einstein\"\n",
    "result = knowledge_graph_llm_pipeline(query)\n",
    "print(\"Knowledge Graph Entity:\", result['Entity'])\n",
    "print(\"Knowledge Graph Info:\", result['Knowledge Graph Info'])\n",
    "print(\"LLM Response:\", result['LLM Response'])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
